{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gc_utils import iteration_name, snapshot_name  # type: ignore\n",
    "from scipy.interpolate import PchipInterpolator, interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first make a plot that shows the mass of Ex-situ formed GCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type_flag(gc, grp, gc_survive_lst):\n",
    "    if gc in gc_survive_lst:\n",
    "        if grp == 0:\n",
    "            # formed in-situ and survived to z = 0\n",
    "            type_flag = 0\n",
    "        elif grp > 0:\n",
    "            # formed ex-situ, accreted and survived to z = 0\n",
    "            type_flag = 2\n",
    "\n",
    "    elif grp < -2:\n",
    "        # formed ex-situ and died before accretion\n",
    "        type_flag = 4\n",
    "\n",
    "    elif grp > 0:\n",
    "        # formed ex-situ, accreted but died before z = 0\n",
    "        type_flag = 3\n",
    "\n",
    "    elif grp == 0:\n",
    "        # formed in-situ, but died before z = 0\n",
    "        type_flag = 1\n",
    "\n",
    "    else:\n",
    "        sys.exit(\"Some GC Missing Type Flag\")\n",
    "\n",
    "    return type_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_data(it, evolve_mass_loss, sim, sim_dir, save_dir, save_dict=True, return_dict=False):\n",
    "    # get required files\n",
    "\n",
    "    proc_file = sim_dir + sim + \"/\" + sim + \"_processed.hdf5\"\n",
    "    proc_data = h5py.File(proc_file, \"r\")  # open processed data file\n",
    "\n",
    "    pub_data = sim_dir + \"snapshot_times_public.txt\"\n",
    "    pub_snaps = pd.read_table(pub_data, comment=\"#\", header=None, sep=r\"\\s+\")\n",
    "    pub_snaps.columns = [\n",
    "        \"index\",\n",
    "        \"scale_factor\",\n",
    "        \"redshift\",\n",
    "        \"time_Gyr\",\n",
    "        \"lookback_time_Gyr\",\n",
    "        \"time_width_Myr\",\n",
    "    ]\n",
    "\n",
    "    mass_dict = {}\n",
    "\n",
    "    it_id = iteration_name(it)\n",
    "    mass_dict[it_id] = {}\n",
    "\n",
    "    src_dat = proc_data[it_id][\"source\"]\n",
    "    ana_mask = np.array(src_dat[\"analyse_flag\"]) == 1\n",
    "\n",
    "    gc_lst = np.array(src_dat[\"gc_id\"])[ana_mask]\n",
    "    gc_survive_lst = np.array(proc_data[it_id][\"snapshots\"][\"snap600\"][\"gc_id\"])\n",
    "\n",
    "    for gc in gc_lst:\n",
    "        gc_id = str(gc)\n",
    "        mass_dict[it_id][gc_id] = {}\n",
    "\n",
    "        idx = np.where(np.array(src_dat[\"gc_id\"])[ana_mask] == gc)[0][0]\n",
    "        grp = np.array(src_dat[\"group_id\"])[ana_mask][idx]\n",
    "\n",
    "        mass_dict[it_id][gc_id][\"group_id\"] = int(grp)\n",
    "        mass_dict[it_id][gc_id][\"type_flag\"] = get_type_flag(gc, grp, gc_survive_lst)\n",
    "\n",
    "        time_lst = []\n",
    "        time_for_lst = []\n",
    "\n",
    "        log_mass_lst = []  # mass at each time\n",
    "        mass_loss_lst = []  # mass loss at each time[1:]\n",
    "        mass_loss_det_lst = []  # mass loss at each time[1:] but taking t_form as 55% of t_form\n",
    "\n",
    "        # get formation information\n",
    "        t_form = np.array(src_dat[\"form_time\"])[ana_mask][idx]\n",
    "\n",
    "        log_mass_form = np.array(src_dat[\"logm_tform\"])[ana_mask][idx]\n",
    "        log_mass_form_det = (\n",
    "            np.log10(1 - evolve_mass_loss) + log_mass_form\n",
    "        )  # corrected for mass loss by evolution\n",
    "\n",
    "        # get other details\n",
    "        t_dis = np.array(src_dat[\"t_dis\"])[ana_mask][idx]\n",
    "\n",
    "        # update relevant lists\n",
    "        time_lst.append(t_form)\n",
    "        time_for_lst.append(t_form - t_form)\n",
    "\n",
    "        # only for accreted (types 2, 3, 4) GCs\n",
    "        if mass_dict[it_id][gc_id][\"type_flag\"] > 1:\n",
    "            time_acc_lst = []\n",
    "\n",
    "            t_acc = np.array(src_dat[\"t_acc\"])[ana_mask][idx]\n",
    "            time_acc_lst.append(t_form - t_acc)\n",
    "\n",
    "        log_mass_lst.append(log_mass_form)\n",
    "\n",
    "        if t_dis == -1:\n",
    "            snap_lst = pub_snaps[(pub_snaps[\"time_Gyr\"] >= t_form)][\"index\"]\n",
    "        else:\n",
    "            snap_lst = pub_snaps[(pub_snaps[\"time_Gyr\"] >= t_form) & (pub_snaps[\"time_Gyr\"] <= t_dis)][\n",
    "                \"index\"\n",
    "            ]\n",
    "\n",
    "        # this has been added to ensure that GCs that form and die between snaps are considered in the for loop\n",
    "        # that gets the details of their death (death loop)\n",
    "        time = t_form\n",
    "\n",
    "        for snap in snap_lst:\n",
    "            snap_id = snapshot_name(snap)\n",
    "            snap_dat = proc_data[it_id][\"snapshots\"][snap_id]\n",
    "\n",
    "            # check, sometimes timing issues with GC formation model\n",
    "            gc_snap_lst = np.array(snap_dat[\"gc_id\"])\n",
    "            if gc not in gc_snap_lst:\n",
    "                continue\n",
    "\n",
    "            time = pub_snaps[pub_snaps[\"index\"] == snap][\"time_Gyr\"].values[0]\n",
    "\n",
    "            snap_idx = np.where(np.array(snap_dat[\"gc_id\"]) == gc)[0][0]\n",
    "            cur_log_mass = np.array(snap_dat[\"mass\"])[snap_idx]\n",
    "\n",
    "            pst_log_mass = log_mass_lst[-1]\n",
    "            pst_mass = 10**pst_log_mass\n",
    "\n",
    "            cur_mass = 10**cur_log_mass\n",
    "\n",
    "            # get mass loss (not logged)\n",
    "            mass_los = pst_mass - cur_mass\n",
    "\n",
    "            # make initial correction to detectable mass loss list\n",
    "            if len(log_mass_lst) == 1:\n",
    "                mass_form_det = 10**log_mass_form_det\n",
    "                mass_los_det = mass_form_det - cur_mass\n",
    "            else:\n",
    "                mass_los_det = mass_los\n",
    "\n",
    "            # update relevant lists\n",
    "            log_mass_lst.append(cur_log_mass)\n",
    "\n",
    "            mass_loss_lst.append(mass_los)\n",
    "            mass_loss_det_lst.append(mass_los_det)\n",
    "\n",
    "            time_lst.append(time)\n",
    "            time_for_lst.append(time - t_form)\n",
    "\n",
    "            # get accretion time\n",
    "            if mass_dict[it_id][gc_id][\"type_flag\"] > 1:\n",
    "                time_acc_lst.append(time - t_acc)\n",
    "\n",
    "        # need to consider full disruption stuff too\n",
    "        # like if in past list but not in current list mass loss is 100%\n",
    "\n",
    "        # (death loop)\n",
    "        # update full disruption details fro GCs that don't survive to z = 0\n",
    "\n",
    "        # if (mass_dict[it_id][gc][\"type_flag\"] != 0) and (mass_dict[it_id][gc][\"type_flag\"] != 2):\n",
    "        #     last_time = pub_snaps[pub_snaps[\"time_Gyr\"] > time][\"time_Gyr\"].values[0]\n",
    "\n",
    "        if t_dis != -1:\n",
    "            # no longer exists\n",
    "            # final_log_mass = np.nan\n",
    "            final_log_mass = None\n",
    "\n",
    "            # past mass\n",
    "            pst_log_mass = log_mass_lst[-1]\n",
    "            pst_mass = 10**pst_log_mass\n",
    "\n",
    "            # as fully disrupted\n",
    "            mass_los = pst_mass\n",
    "\n",
    "            time_lst.append(t_dis)\n",
    "            time_for_lst.append(t_dis - t_form)\n",
    "\n",
    "            # get accretion time\n",
    "            if mass_dict[it_id][gc_id][\"type_flag\"] > 1:\n",
    "                time_acc_lst.append(t_dis - t_acc)\n",
    "\n",
    "            log_mass_lst.append(final_log_mass)\n",
    "            mass_loss_lst.append(mass_los)\n",
    "            mass_loss_det_lst.append(mass_los)\n",
    "\n",
    "        # update dictionary\n",
    "        mass_dict[it_id][gc_id][\"time\"] = time_lst\n",
    "        mass_dict[it_id][gc_id][\"form_time\"] = time_for_lst\n",
    "\n",
    "        if mass_dict[it_id][gc_id][\"type_flag\"] > 1:\n",
    "            mass_dict[it_id][gc_id][\"acc_time\"] = time_acc_lst\n",
    "\n",
    "        mass_dict[it_id][gc_id][\"log_mass\"] = log_mass_lst\n",
    "        mass_dict[it_id][gc_id][\"mass_loss\"] = mass_loss_lst\n",
    "        mass_dict[it_id][gc_id][\"mass_loss_detectable\"] = mass_loss_det_lst\n",
    "\n",
    "    # close file\n",
    "    proc_data.close()\n",
    "\n",
    "    if save_dict:\n",
    "        save_file = save_dir + \"/\" + it_id + \"_gc_mass_data.json\"\n",
    "\n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "\n",
    "        with open(save_file, \"w\") as f:\n",
    "            json.dump(mass_dict, f, indent=4)  # `indent=4` makes it more readable\n",
    "\n",
    "    if return_dict:\n",
    "        return mass_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a JSON file\n",
    "evolve_mass_loss = 0.45\n",
    "\n",
    "it_min = 0\n",
    "it_max = 100\n",
    "\n",
    "sim = \"m12i\"\n",
    "\n",
    "sim_dir = \"/Users/z5114326/Documents/simulations/\"\n",
    "save_dir = \"../data/gc_mass_data/\" + sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it in range(it_min, it_max + 1):\n",
    "    get_mass_data(it, evolve_mass_loss, sim, sim_dir, save_dir, save_dict=True, return_dict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = 0\n",
    "\n",
    "it_id = iteration_name(it)\n",
    "\n",
    "data_file = save_dir + \"/\" + it_id + \"_gc_mass_data.json\"\n",
    "\n",
    "# open json file as dict\n",
    "with open(data_file, \"r\") as file:\n",
    "    mass_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we plot the mass of Ex-situ clusters as a function of accreted time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['group_id', 'type_flag', 'time', 'form_time', 'log_mass', 'mass_loss', 'mass_loss_detectable'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_dict[it_id][\"119998556\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for ** or pow(): 'int' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m plot_dict[it_id][\u001b[38;5;28mstr\u001b[39m(type_flag)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mass_dict[it_id][gc_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     30\u001b[0m plot_dict[it_id][\u001b[38;5;28mstr\u001b[39m(type_flag)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mform_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mass_dict[it_id][gc_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mform_time\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 32\u001b[0m plot_dict[it_id][\u001b[38;5;28mstr\u001b[39m(type_flag)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmass\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmass_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mit_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mgc_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlog_mass\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     33\u001b[0m plot_dict[it_id][\u001b[38;5;28mstr\u001b[39m(type_flag)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmass_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(mass_dict[it_id][gc_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmass_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     34\u001b[0m plot_dict[it_id][\u001b[38;5;28mstr\u001b[39m(type_flag)][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmass_loss_detectable\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (mass_dict[it_id][gc_id][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmass_loss_detectable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     36\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for ** or pow(): 'int' and 'list'"
     ]
    }
   ],
   "source": [
    "plot_dict = {}\n",
    "\n",
    "plot_dict[it_id] = {}\n",
    "\n",
    "plot_dict[it_id][\"0\"] = {}\n",
    "plot_dict[it_id][\"1\"] = {}\n",
    "plot_dict[it_id][\"2\"] = {}\n",
    "plot_dict[it_id][\"3\"] = {}\n",
    "plot_dict[it_id][\"4\"] = {}\n",
    "\n",
    "# set up dictionary\n",
    "for type_flag in range(0, 5):\n",
    "    plot_dict[it_id][str(type_flag)] = {}\n",
    "\n",
    "    plot_dict[it_id][str(type_flag)][\"time\"] = []\n",
    "    plot_dict[it_id][str(type_flag)][\"form_time\"] = []\n",
    "\n",
    "    plot_dict[it_id][str(type_flag)][\"mass\"] = []\n",
    "    plot_dict[it_id][str(type_flag)][\"mass_loss\"] = []\n",
    "    plot_dict[it_id][str(type_flag)][\"mass_loss_detectable\"] = []\n",
    "\n",
    "    if type_flag > 1:\n",
    "        plot_dict[it_id][str(type_flag)][\"acc_time\"] = []\n",
    "\n",
    "# fill type dict\n",
    "for gc_id in mass_dict[it_id]:\n",
    "    type_flag = mass_dict[it_id][gc_id][\"type_flag\"]\n",
    "\n",
    "    time_lst = mass_dict[it_id][gc_id][\"time\"]\n",
    "    form_time_lst = mass_dict[it_id][gc_id][\"form_time\"]\n",
    "\n",
    "    log_mass_lst = mass_dict[it_id][gc_id][\"log_mass\"]\n",
    "\n",
    "    mass_loss_lst = mass_dict[it_id][gc_id][\"mass_loss\"]\n",
    "    mass_loss_detectable_lst = mass_dict[it_id][gc_id][\"mass_loss_detectable\"]\n",
    "\n",
    "    if type_flag <= 1:\n",
    "        for time, form_time, log_mass in zip(time_lst, form_time_lst, log_mass_lst):\n",
    "            plot_dict[it_id][str(type_flag)][\"time\"].append(time)\n",
    "            plot_dict[it_id][str(type_flag)][\"form_time\"].append(form_time)\n",
    "\n",
    "            if log_mass is not None:\n",
    "                mass = 10**log_mass\n",
    "                plot_dict[it_id][str(type_flag)][\"mass\"].append(mass)\n",
    "            else:\n",
    "                plot_dict[it_id][str(type_flag)][\"mass\"].append(0)\n",
    "\n",
    "    # plot_dict[it_id][str(type_flag)][\"time\"].append(mass_dict[it_id][gc_id][\"time\"])\n",
    "    # plot_dict[it_id][str(type_flag)][\"form_time\"].append(mass_dict[it_id][gc_id][\"form_time\"])\n",
    "\n",
    "    # # plot_dict[it_id][str(type_flag)][\"mass\"].append(10 ** (mass_dict[it_id][gc_id][\"log_mass\"]))\n",
    "    # plot_dict[it_id][str(type_flag)][\"mass_loss\"].append(mass_dict[it_id][gc_id][\"mass_loss\"])\n",
    "    # plot_dict[it_id][str(type_flag)][\"mass_loss_detectable\"].append(\n",
    "    #     10 ** (mass_dict[it_id][gc_id][\"mass_loss_detectable\"])\n",
    "    # )\n",
    "\n",
    "    # if type_flag > 1:\n",
    "    #     plot_dict[it_id][str(type_flag)][\"acc_time\"].append(mass_dict[it_id][gc_id][\"acc_time\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.029\n",
      "3.762\n",
      "3.735\n",
      "3.709\n",
      "3.67\n",
      "3.611\n",
      "3.575\n",
      "3.476\n",
      "3.335\n",
      "2.948\n"
     ]
    }
   ],
   "source": [
    "for mass in mass_dict[it_id][gc_id][\"log_mass\"]:\n",
    "    if mass is not None:\n",
    "        print(mass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
